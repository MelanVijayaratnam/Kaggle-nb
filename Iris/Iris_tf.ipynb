{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center\">Logistic Regression with TensorFlow</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Introduction</u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to familiarize with the <u>TensorFlow</u>, the Deep Learning library build by Google in November 2015. <br>\n",
    "Now it is the framework that it is the most used and we will use it in order to build a Logistic Regression model using the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Package</u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the packages that we need to achieve our goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Iris dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify things, we will only consider 2 attributes and 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHg5JREFUeJzt3X+QVPW55/H34zQRRuVq6dSGAgFTiT+CgwygYnJLvYKR\nKIWpUjds4Q9IKBaJGDfXRNlUqUtiUresXPXeKySjSTSBRNzRJJrKui5eXU2VUUH5pYhyDT8G3ABD\nRAhgMvLsH90jMz3N9DndfabP98znVXVqpk9/+8zzPefw0P09z/m2uTsiIpItx9Q7ABERqT0ldxGR\nDFJyFxHJICV3EZEMUnIXEckgJXcRkQxSchcRySAldxGRDFJyFxHJoMjJ3cwazOx1M/ttiedmmdku\nM1tdWOaU297UqVMd0KJFixYt8ZZIclEbAl8HNgBDj/L8cne/KerGdu/eHeNPi4hIHJHeuZvZCOAK\n4KFkwxERkVqIOixzH/At4HAfba4ys7Vm1mZmp5ZqYGZzzWylma3ctWtX3FhFRCSissndzKYBO919\nVR/NngJGu/tYYAXwSKlG7t7q7hPdfWJTU1NFAYuISHlRxtw/D0w3s8uBwcBQM1vq7td2NXD3jm7t\nHwT+qbZhikja/e1vf6O9vZ1Dhw7VO5RMGDx4MCNGjGDQoEEVvb5scnf3hcBCADO7GLi1e2IvrB/m\n7u8VHk4nf+FVRAaQ9vZ2TjjhBEaPHo2Z1TucoLk7HR0dtLe3c9ppp1W0jYrr3M1skZlNLzy82cze\nMLM1wM3ArEq3KyJhOnToECeffLISew2YGSeffHJVn4JiJXd3f97dpxV+v8Pdnyz8vtDdx7j7Oe7+\nD+7+VsURiaTMsmUwejQcc0z+57Jl9Y4ovZTYa6fafRmnzl1kwFm2DObOhQMH8o+3bMk/Bpg5s35x\niZSj6QdE+vDtbx9J7F0OHMivl7A9/PDD7Nixo95hJEbJXaQPW7fGWy/hUHIXGcBGjoy3XqJL4lrG\nX/7yF6644grOOecczj77bJYvX86qVau46KKLmDBhApdddhnvvfcebW1trFy5kpkzZzJu3DgOHjzI\ns88+S0tLC83NzXzlK1/hww8/BOD222/ns5/9LGPHjuXWW28F4KmnnuL888+npaWFKVOm8Kc//an6\n4GvN3euyTJgwwUXSbulS98ZGdziyNDbm10tPb775ZuS2Se3XtrY2nzNnzseP33//fb/gggt8586d\n7u7+6KOP+uzZs93d/aKLLvJXX33V3d0PHjzoI0aM8I0bN7q7+3XXXef33nuvd3R0+Omnn+6HDx92\nd/c///nP7u6+Z8+ej9c9+OCD/o1vfKO6wI/iKPs0Uo7VO3eRPsycCa2tMGoUmOV/trbqYmq1krqW\n0dzczIoVK7jtttt48cUX2bZtG+vXr+fSSy9l3LhxfPe736W9vb3X6zZu3Mhpp53G6aefDsANN9zA\nCy+8wNChQxk8eDBz5szhiSeeoLGxEcjX9F922WU0Nzdzzz338MYbb1QXeAKU3EXKmDkTNm+Gw4fz\nP5XYq5fUtYzTTz+dVatW0dzczMKFC3n88ccZM2YMq1evZvXq1axbt45nnnmm1+vcS8+km8vleOWV\nV7jqqqv49a9/zdSpUwFYsGABN910E+vWreNHP/pRKu/KVXIXkX6X1LWMHTt20NjYyLXXXsutt97K\nyy+/zK5du3jppZeA/BQJXe+yTzjhBPbt2wfAmWeeyebNm9m0aRMAP//5z7nooovYv38/e/fu5fLL\nL+e+++5j9erVAOzdu5fhw4cD8MgjJafSqjvVuYtIv7v77p73DwA0NubXV2PdunV885vf5JhjjmHQ\noEEsWbKEXC7HzTffzN69e+ns7OSWW25hzJgxzJo1i3nz5jFkyBBeeuklfvrTn3LNNdfQ2dnJueee\ny7x589izZw9XXnklhw4dwt259957Abjrrru45pprGD58OJMmTeKPf/xjdYEnwI72cSRpEydO9JUr\nV9blb4tI7W3YsIGzzjorcvtly/Jj7Fu35t+x3323hryKHWWfRrp1Ve/cRaQuZs5UMk+SxtxFRDJI\nyV1EJIOU3EVEMkjJXUQkg5TcRUQySMldMkNfqiFJuOOOO1ixYkXs1z3//PNMmzYtgYiiUSmkZIK+\nVEOq8fFkW8f0fr+7aNGifomhs7OTXK52KVnv3CUT9KUaAUrgo9Ztt93G4sWLP35811138YMf/IB7\n7rmHc889l7Fjx3LnnXcCsHnzZs466yzmz5/P+PHj2bZtG7NmzeLss8+mubn547tRZ82aRVtbGwCv\nvvoqn/vc5zjnnHM477zz2LdvH4cOHWL27Nk0NzfT0tLCc8891yuuPXv28KUvfYmxY8cyadIk1q5d\n+3F8c+fO5Qtf+ALXX3991f3vTsldMkFfqhGYro9aW7bkZ/zt+qhVZYKfMWMGy5cv//jxY489RlNT\nE++88w6vvPIKq1evZtWqVbzwwgtAfjbI66+/ntdff53du3ezfft21q9fz7p165g9e3aPbf/1r3/l\ny1/+Mvfffz9r1qxhxYoVDBkyhAceeADIT33wy1/+khtuuKHXRGJ33nknLS0trF27lu9973s9Evmq\nVav4zW9+wy9+8Yuq+l5MyV0yQV+qEZiEPmq1tLSwc+dOduzYwZo1azjppJNYu3YtzzzzDC0tLYwf\nP5633nqLd955B4BRo0YxadIkAD71qU/x7rvvsmDBAp5++mmGDh3aY9sbN25k2LBhnHvuuQAMHTqU\nXC7H73//e6677jogPwHZqFGjePvtt3u8tnubSy65hI6ODvbu3QvA9OnTGTJkSFX9LkXJXTLh7rvz\nE091V4uJqCQhCX7Uuvrqq2lra2P58uXMmDEDd2fhwoUfT/u7adMmvvrVrwJw3HHHffy6k046iTVr\n1nDxxRfzwAMPMGfOnB7bdXfMek/rEmV+rlJturbVPYZaUnKXTNCXagQmwY9aM2bM4NFHH6WtrY2r\nr76ayy67jJ/85Cfs378fgO3bt7Nz585er9u9ezeHDx/mqquu4jvf+Q6vvfZaj+fPPPNMduzYwauv\nvgrAvn376Ozs5MILL2RZYTjp7bffZuvWrZxxxhk9Xtu9zfPPP88pp5zS65NBralaRjJDE1EFJKk5\nf4ExY8awb98+hg8fzrBhwxg2bBgbNmzgggsuAOD4449n6dKlNDQ09Hjd9u3bmT17NocPHwbg+9//\nfo/nP/GJT7B8+XIWLFjAwYMHGTJkCCtWrGD+/PnMmzeP5uZmcrkcDz/8MMcee2yP1951113Mnj2b\nsWPH0tjY2C9zwGvKX6mapm4ViD/lr06c8jTlr9SN6sulYvqolSiNuUtVVF8ukk5K7lIV1ZdLd/Ua\n5s2iavelkrtURfXl0mXw4MF0dHQowdeAu9PR0cHgwYMr3obG3KUqCRY9SGBGjBhBe3s7u3btqnco\nmTB48GBGjBhR8euV3KUqXdfDVPQggwYN4rTTTqt3GFIQuRTSzBqAlcB2d59W9NyxwM+ACUAH8GV3\n39zX9lQKKSJSkUilkHHG3L8ObDjKc18F/uzunwbuBf4pxnZFMkNzyktaREruZjYCuAJ46ChNrgS6\nbrlqAyZbqUkYRDIsoYkORSoS9Z37fcC3gMNHeX44sA3A3TuBvcDJVUcnEhDV/EualE3uZjYN2Onu\nq/pqVmJdr8F8M5trZivNbKWuqEvWqOZf0iTKO/fPA9PNbDPwKHCJmS0tatMOnApgZjng74A9xRty\n91Z3n+juE5uamqoKXCRtVPMvaVI2ubv7Qncf4e6jgRnAv7v7tUXNngRuKPx+daGN7mSQAUVzykua\nVHyHqpktMrPphYc/Bk42s03AN4DbaxGcSEg0p7ykiab8FREJS83r3EX61fz5kMvl3wXncvnHIhKN\nph+QVJo/H5YsOfL4o4+OPF68uD4xiYREwzKSSrlcPqEXa2iAzs7+j0ckRTQsI+Eqldj7Wi8iPSm5\nSyoVfXdx2fUi0pOSu6RS1/ewRl0vIj3pgqqkUtdF09bW/FBMQ0M+setiqkg0uqAqIhIWXVCVyk2Z\nkq8v71qmTKl3RPWjOdolREru0suUKfDssz3XPfvswEzwmqNdQqVhGemlr69ZGWjTwY0enU/oxUaN\ngs2b+zsaEUDDMiLV0xztEiold5E+aI52CZWSu/QyeXK89VmmOdolVEru0suKFb0T+eTJ+fUDjeZo\nl1DpgqqISFh0QVUql1Rtd5ztqr5cpHKafkB66artPnAg/7irthuqG46Is92kYhAZKDQsI70kVdsd\nZ7uqLxc5qkjDMkru0ssxx5S+WckMDh/un+0mFYNIBmjMXSqTVG13nO2qvlykOkru0ktStd1xtqv6\ncpHqKLlLL0nVdsfZrurLRaqjMXcRkbBozD1JIdZghxiziFRGde4VCLEGO8SYRaRyGpapQIg12CHG\nLCIlaVgmKSHO8R1izCJSOSX3CoRYgx1izCJSOSX3CoRYgx1izCJSOSX3CoRYgx1izCJSubIXVM1s\nMPACcCz56po2d7+zqM0s4B5ge2HVv7n7Q31tN+QLqiIidVSzC6ofApe4+znAOGCqmU0q0W65u48r\nLH0mdqmP+fMhl8u/c8/l8o9r0TYt9fNpiUMkDcrWuXv+rf3+wsNBhaU+9ZNSsfnzYcmSI48/+ujI\n48WLK2+blvr5tMQhkhaR6tzNrAFYBXwaeMDdbyt6fhbwfWAX8Dbw39x9W1/b1LBM/8rl8km6WEMD\ndHZW3jYt9fNpiUOkH9R+PnczOxH4FbDA3dd3W38ysN/dPzSzecB/dvdLSrx+LjAXYOTIkRO2lPrX\nKImwPk6H4lMgTtu0zLueljhE+kHtb2Jy9/eB54GpRes73P3DwsMHgQlHeX2ru09094lNTU1x/rRU\nqaEh+vo4bdNSP5+WOETSomxyN7Omwjt2zGwIMAV4q6jNsG4PpwMbahmkVK9r/DnK+jht01I/n5Y4\nRFLD3ftcgLHA68BaYD1wR2H9ImB64ffvA28Aa4DngDPLbXfChAku/evGG90bGtwh//PGG2vTdulS\n91Gj3M3yP5curXXk0aQlDpGElc3b7q6Jw0REAqOJw5KUVE11nPryJLcdp38h7ovgqIhf4or6Fr/W\nS8jDMkuXujc25ocsupbGxuqHAW68sec2u5a+hkSS2Hac/oW4L4KT1E6WUGlYJilJ1VTHqS9Pcttx\n+hfivgiOivilp9rXuddSyMk9qZrqOPXlSW47Tv9C3BfBURG/9KQx96QkVVMdp748yW3H6V+I+yI4\nKuKXCii5VyCpmuo49eVJbjtO/0LcF8FREb9UIurgfK2XkC+ouidXUx2nvjzJbcfpX4j7Ijgq4pcj\ndEFVRCSDNOYuPaWhdl0CpxMjGGXnc5dsiDPfueZGl5J0YgRFwzIDRBpq1yVwOjHSQnXuckQaatcl\ncDox0kJj7nJEGmrXJXA6MYKi5D5ApKF2XQKnEyMoSu4DxMyZ0NqaHx41y/9sbS19HSxOWxlAdGIE\nRWPuIiJh0Zg7JFeWG2e7aZmXXCXKKZP1A5L1/sVRj30R9VbWWi/9Mf1AUtNgx9luWuYl15TgKZP1\nA5L1/sVR+32h6QeSKsuNs920zEuuEuWUyfoByXr/4qj9vlCde1JluXG2m5Z5yVWinDJZPyBZ718c\ntd8XGnNPqiw3znbTMi+5SpRTJusHJOv9i6NO+yLTyT2pstw4203LvOQqUU6ZrB+QrPcvjnrti6iD\n87Ve+ms+96SmwY6z3bTMS64pwVMm6wck6/2Lo7b7QhdURUQySGPuSUpD/fyUKflrMl3LlCm1iUEk\nU5K60STtdfxR3+LXegn5a/bSUD8/eXLp+vnJk6uLQSRTkrrRpL51/BqWSUoa6ufTUmIpkmpJ3WhS\n3zp+1bknRfXzIoFI6h9Kfev4NeaelDTUz4tIBEndaBLAP1Yl9wqkoX5+8uTS2zjaepEBKakbTUKo\n4486OF/rJeQLqu7pqJ8vvqiqi6kiJSR1o0n96vh1QVVEJINqM+ZuZoPN7BUzW2Nmb5jZ/yjR5lgz\nW25mm8zsZTMbHT/eaOKWlqa9FLVYnJLcrO+LRANOckdHlWT/gjvYMWT+xK+Rcm/tyf8vcXzh90HA\ny8CkojbzgR8Wfp8BLC+33UqGZeKWloY2pXScktys74tEA05yR0eVZP+CO9gxZP7EjyTSsEyscXKg\nEXgNOL9o/f8GLij8ngN2UyizPNpSSXIfNar0v8lRo2rTvt66hgWLl4aG3m2zvi8SDTjJHR1Vkv0L\n7mDHkPkTP5JI+TrSmLuZNQCrgE8DD7j7bUXPrwemunt74fF/FP4D2F3Ubi4wF2DkyJETtpS6CaAP\ncUtLQ5tSOk5Jbtb3RaIBJ7mjo0qyf8Ed7Bgyf+JHUrs6d3f/yN3HASOA88zs7Ah/rNcedfdWd5/o\n7hObmpqi/Oke4paWBlCK2kOcktys74tEA05yR0eVZP+CO9gxZP7Er51Yde7u/j7wPDC16Kl24FQA\nM8sBfwfsqUF8PcQtLQ2hFLW7OCW5Wd8XiQac5I6OKsn+BXewY8j8iV9D5cZtgCbgxMLvQ4AXgWlF\nbb5Gzwuqj5XbbqV17nFLS0ObUjpOSW7W90WiASe5o6NKsn/BHewYMn/il1WbMXczGws8AjSQf6f/\nmLsvMrNFwEp3f9LMBgM/B1rIv2Of4e7v9rVd1bmLiFREE4eJiGSQJg6DgXv/gpQR58RIw0mU5I07\nod2klYbjEYKo4ze1Xvpjbpls3r8gVYtzYqThJEryxp3QbtJKw/Gov9rVuSehP4Zl6jufvqRWnBMj\nDSdR3BjS0L/QthsWjbln8/4FqVqcEyMNJ1GSN+6EdpNWGo5H/WnMfQDfvyB9iXNipOEkSvLGndBu\n0krD8QhEppP7QL5/QfoQ58RIw0mU5I07od2klYbjEYqog/O1Xvrryzqyd/+C1EScEyMNJ1GSN+6E\ndpNWGo5HfemCqohIBmnMXaQm4nyxR1qEFnNaatfTEkctRH2LX+sl9O9QlQEizhd7pEVoMaeldj0t\ncZSnYRmRquVy8NFHvdc3NEBnZ//HE0VoMaeldj0tcZSnYRmRqpVKkn2tT4PQYt66Nd76rMdRI0ru\nIn2J88UeaRFazGmpXU9LHDWi5C7Slzhf7JEWocWcltr1tMRRK1EH52u96IKqBCPOF3ukRWgxp6V2\nPS1x9E0XVEVEMkgXVKWfhFgbnFTMSdWXh7iPpb6ivsWv9aJhmYwIpzb4iKRiTqq+PMR9LEnSsIz0\ng3Bqg49IKuak6stD3MeSJM3nLv0gxPm1k4rZ+vg3V82/sxD3sSRJY+7SD0KsDU4q5qTqy0Pcx1J3\nSu5SnRBrg5OKOan68hD3sdRf1MH5Wi+6oJohYdQG95RUzEnVl4e4jyUpuqAqIpJBGnOXASapWvA4\n21U9uqRErt4BiNTEsmX5se0DB/KPt2w5MtY9c2b/bDepGEQqoGEZyYakasHjbFf16NI/VOcuA0hS\nteBxtqt6dOkfGnOXASSpWvA421U9uqSIkrtkQ1K14HG2q3p0SREld8mGmTOhtTU/vm2W/9naWv2F\nzDjbTSoGkQqUHXM3s1OBnwGfBA4Dre5+f1Gbi4HfAH8srHrC3Rf1tV2NuYuIVKRmY+6dwD+6+1nA\nJOBrZvbZEu1edPdxhaXPxC4BCLFeW/XoydN+C0fUW1m7FvLv0C8tWncx8Ns429H0AykW4vzhcWIO\nsX9poP2WFrWffsDMRgMvAGe7+wfd1l8MPA60AzuAW939jb62pWGZFAuxXlv16MnTfkuL2ta5m9nx\nwP8F7nb3J4qeGwocdvf9ZnY5cL+7f6bENuYCcwFGjhw5YUupE0XqL8R6bdWjJ0/7LS1qV+duZoPI\nvzNfVpzYAdz9A3ffX/j9d8AgMzulRLtWd5/o7hObmpqi/GmphxDrtVWPnjztt6CUTe5mZsCPgQ3u\n/s9HafPJQjvM7LzCdjtqGaj0oxDrtVWPnjztt7CUG5QH/h5wYC2wurBcDswD5hXa3AS8AawB/gB8\nrtx2dUE15UKcPzxOzCH2Lw2039JA87mLiGSQ5pbJPNUc9zR/PuRy+Qt8uVz+scgApfncQ6W5w3ua\nPx+WLDny+KOPjjxevLg+MYnUkYZlQqWa455yuXxCL9bQAJ2d/R+PSHI0LJNpW7fGW591pRJ7X+tF\nMk7JPVSqOe6poSHeepGMU3IPlWqOe+q63hB1vUjGKbmHSnOH97R4Mdx445F36g0N+ce6mCoDlC6o\nioiERRdU48p82XjWO5j1/qWB9nE4ot7KWuslbdMPZH6q6qx3MOv9SwPt47TQ9ANxZL5sPOsdzHr/\n0kD7OC1qO597raUtuWd+quqsdzDr/UsD7eO00Jh7HJkvG896B7PevzTQPg6KkntB5svGs97BrPcv\nDbSPwxJ1cL7WS9ouqLoPgKmqs97BrPcvDbSP00AXVEVEMkhj7iKZkWR9uWrXM0nzuYukXZJz9+t7\nATJLwzIiaZdkfblq10OkYRmRTEhy7n59L0BmKbmLpF2S9eWqXc8sJXeRtEuyvly165ml5C6SdknO\n3a/vBcgsXVAVEQmLLqiKiAxUSu4iIhmk5C4ikkFK7iIiGaTkLiKSQUruIiIZpOQuIpJBSu4iIhlU\nNrmb2alm9pyZbTCzN8zs6yXamJn9i5ltMrO1ZjY+mXClKpq3W2TAiDKfeyfwj+7+mpmdAKwys//j\n7m92a/NF4DOF5XxgSeGnpIXm7RYZUMq+c3f399z9tcLv+4ANwPCiZlcCPyt8v98fgBPNbFjNo5XK\nffvbRxJ7lwMH8utFJHNijbmb2WigBXi56KnhwLZuj9vp/R8AZjbXzFaa2cpdu3bFi1Sqo3m7RQaU\nyMndzI4HHgducfcPip8u8ZJeM5K5e6u7T3T3iU1NTfEilepo3m6RASVScjezQeQT+zJ3f6JEk3bg\n1G6PRwA7qg9PakbzdosMKFGqZQz4MbDB3f/5KM2eBK4vVM1MAva6+3s1jFOqpXm7RQaUsvO5m9nf\nAy8C64DDhdX/HRgJ4O4/LPwH8G/AVOAAMNvd+5ysXfO5i4hUJNJ87mVLId399+U25vn/Ib4WLS4R\nEUma7lAVEckgJXcRkQxSchcRySAldxGRDFJyFxHJICV3EZEMUnIXEcmgsjcxJfaHzXYBW+ryx8s7\nBdhd7yASpP6FK8t9A/Uvit3uPrVco7ol9zQzs5XuPrHecSRF/QtXlvsG6l8taVhGRCSDlNxFRDJI\nyb201noHkDD1L1xZ7huofzWjMXcRkQzSO3cRkQwa0MndzBrM7HUz+22J52aZ2S4zW11Y5tQjxmqY\n2WYzW1eIv9fk+YUvV/kXM9tkZmvNbHw94qxEhL5dbGZ7ux2/O+oRZ6XM7EQzazOzt8xsg5ldUPR8\nsMcOIvUv2ONnZmd0i3u1mX1gZrcUtUn8+JWdzz3jvg5sAIYe5fnl7n5TP8aThH9w96PV1X4R+Exh\nOR9YUvgZir76BvCiu0/rt2hq637gaXe/2sw+ARR9R2Lwx65c/yDQ4+fuG4FxkH8DCWwHflXULPHj\nN2DfuZvZCOAK4KF6x1JHVwI/87w/ACea2bB6BzXQmdlQ4ELyX2+Ju//V3d8vahbssYvYv6yYDPyH\nuxffsJn48RuwyR24D/gWR746sJSrCh+Z2szs1D7apZUDz5jZKjObW+L54cC2bo/bC+tCUK5vABeY\n2Roz+19mNqY/g6vSp4BdwE8Lw4YPmdlxRW1CPnZR+gfhHr/uZgC/LLE+8eM3IJO7mU0Ddrr7qj6a\nPQWMdvexwArgkX4JrrY+7+7jyX8E/JqZXVj0fKmvTwylfKpc314DRrn7OcC/Ar/u7wCrkAPGA0vc\nvQX4C3B7UZuQj12U/oV8/AAoDDdNB/5nqadLrKvp8RuQyR34PDDdzDYDjwKXmNnS7g3cvcPdPyw8\nfBCY0L8hVs/ddxR+7iQ/5ndeUZN2oPsnkhHAjv6Jrjrl+ubuH7j7/sLvvwMGmdkp/R5oZdqBdnd/\nufC4jXwyLG4T5LEjQv8CP35dvgi85u5/KvFc4sdvQCZ3d1/o7iPcfTT5j03/7u7Xdm9TNP41nfyF\n12CY2XFmdkLX78AXgPVFzZ4Eri9cuZ8E7HX39/o51Nii9M3MPmlmVvj9PPLnekd/x1oJd/9/wDYz\nO6OwajLwZlGzII8dROtfyMevm/9C6SEZ6IfjN9CrZXows0XASnd/ErjZzKYDncAeYFY9Y6vAfwJ+\nVfj3kQN+4e5Pm9k8AHf/IfA74HJgE3AAmF2nWOOK0rergRvNrBM4CMzwsO7YWwAsK3y0fxeYnZFj\n16Vc/4I+fmbWCFwK/Ndu6/r1+OkOVRGRDBqQwzIiIlmn5C4ikkFK7iIiGaTkLiKSQUruIiIZpOQu\nIpJBSu4iIhmk5C4ikkH/HwzZ3k53KeYVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b2f2a8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:100, 1:3].values\n",
    "y = data.iloc[:100, 5].values\n",
    "\n",
    "m = 100\n",
    "\n",
    "setosa = plt.scatter(X[:50, 0], X[:50, 1], c='b', label=\"setosa\")\n",
    "versicolor = plt.scatter(X[50:, 0], X[50:, 1], c='r', label=\"versicolor\")\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must not forget to add an extra bias feature ($x_0 = 1$) to every instance. <br>\n",
    "For this, we just need to add a column full of 1s on the left of the input matrix <b>X</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_with_bias = np.c_[np.ones((m, 1)), X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reshape y_train to make it a column vector (i.e. a 2D array with a single column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_column_vector = y.reshape(-1, 1)\n",
    "y_column_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert the Species into number, in this case, we will impose <br>\n",
    "'Iris-setosa' = 1 and 'Iris-versicolor' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_bin = (np.where(y_column_vector == 'Iris-setosa', 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = np.concatenate((X_with_bias, y_bin), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Train/Test set split</u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the loaded dataset into two, <b>80%</b> of which we will use to train our model and <b>20%</b> that we will hold back as a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # To make output consistent in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    \n",
    "    return data[train_indices], data[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (80, 4) Test size: (20, 4)\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "train, test = split_train_test(full_data, test_ratio=test_ratio)\n",
    "print(\"Train size:\", train.shape, \"Test size:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (80, 3) y_train.shape: (80, 1)\n",
      "X_test.shape: (20, 3) y_test.shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train[:, 0:3], train[:, -1].reshape(-1, 1)\n",
    "X_test, y_test = test[:, 0:3], test[:, -1].reshape(-1, 1)\n",
    "print(\"X_train.shape:\", X_train.shape, \"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape, \"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate training batches</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation we will just pick random instances from the training set for each batch. This means that a single batch may contain the same instance multiple times, and also a single epoch may not cover all the training instances (in fact, it will generally cover only about two thirds of the instances). However, inpractice this is not an issue and it simplifies the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>TensorFlow</u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's the reset the default graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessed data has two input features, the sepal length and the sepal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Logistic Regression computes a weighted sum of the inputs and then it applies the sigmoid function to the result, which gives us the estimated probability for the positive class:\n",
    "$\\hat p = h_{\\boldsymbol{\\theta}}(x) = \\sigma(\\boldsymbol{\\theta}^{T}.\\boldsymbol{x})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $\\boldsymbol{\\theta}$ is the parameter vector, containing the bias term $\\theta_0$ and the weights $\\theta_1, \\theta_2, ..., \\theta_n$. <br>\n",
    "The input vector $\\boldsymbol{x}$ contains a constant term $x_0 = 1$, as well as all the input features $x_1, x_2, ..., x_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the <b>logistic_regression()</b> function to create the graph. We will leave out the definition of the inputs X and the targets y. We could include them here, but leaving them out will make it easier to use this function in a wide range of use cases (e.g. perhaps we will want to add some preprocessing steps for the inputs before we feed them to the Logistic Regression model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    \n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        \n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "                \n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "            \n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('loss_loss', loss)\n",
    "            \n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "            \n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a little function to get the name of the log directory to save the summaries for Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the graph using the <b>logistic_regression()</b> function. We will also create the <b>FileWriter</b> to save the summaries to the log directory for Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 2 \n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we can train the model!<br>\n",
    "We will start by checking whether a previous training session was interrupted, and if so we will load the checkpoint and conitnue training from the epoch number we saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 100 # number of examples\n",
    "n_epochs = 10001\n",
    "batch_size = 10\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 1.06961\n",
      "Epoch: 500 \tLoss: 0.11557\n",
      "Epoch: 1000 \tLoss: 0.0730393\n",
      "Epoch: 1500 \tLoss: 0.0574932\n",
      "Epoch: 2000 \tLoss: 0.0484852\n",
      "Epoch: 2500 \tLoss: 0.0426669\n",
      "Epoch: 3000 \tLoss: 0.0367927\n",
      "Epoch: 3500 \tLoss: 0.0332635\n",
      "Epoch: 4000 \tLoss: 0.0313672\n",
      "Epoch: 4500 \tLoss: 0.0287894\n",
      "Epoch: 5000 \tLoss: 0.0270536\n",
      "Epoch: 5500 \tLoss: 0.0259418\n",
      "Epoch: 6000 \tLoss: 0.0237918\n",
      "Epoch: 6500 \tLoss: 0.0233619\n",
      "Epoch: 7000 \tLoss: 0.0223086\n",
      "Epoch: 7500 \tLoss: 0.0212911\n",
      "Epoch: 8000 \tLoss: 0.0199751\n",
      "Epoch: 8500 \tLoss: 0.0199696\n",
      "Epoch: 9000 \tLoss: 0.0187173\n",
      "Epoch: 9500 \tLoss: 0.0179285\n",
      "Epoch: 10000 \tLoss: 0.0178644\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # If the checkpoint file exists, restore the model\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else: \n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "#             print(\"X_batch shape:\", X_batch.shape, \"y_batch.shape:\", y_batch.shape)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test,y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "        \n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can make predictions by just classifying as positive all the instances whose estimated probability is greater or equal to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True]], dtype=bool)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing ! All the examples from the test set were classified correctly using the Logistic Regression model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the graph function in Juputer notebook by adding the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.21654012033140546&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\003\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;logistic_regression/model/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logistic_regression/model/random_uniform/max&quot;\\n  input: &quot;logistic_regression/model/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/model/random_uniform/RandomUniform&quot;\\n  input: &quot;logistic_regression/model/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logistic_regression/model/random_uniform/mul&quot;\\n  input: &quot;logistic_regression/model/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logistic_regression/model/theta&quot;\\n  input: &quot;logistic_regression/model/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/model/theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/logits&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;logistic_regression/model/theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/model/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;logistic_regression/model/logits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logistic_regression/model/Sigmoid&quot;\\n  input: &quot;logistic_regression/train/loss/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;logistic_regression/train/loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;y&quot;\\n  input: &quot;logistic_regression/train/loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;logistic_regression/train/loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logistic_regression/train/loss/sub/x&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logistic_regression/train/loss/sub_1/x&quot;\\n  input: &quot;logistic_regression/model/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0000000116860974e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logistic_regression/train/loss/sub_1&quot;\\n  input: &quot;logistic_regression/train/loss/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Log_1&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;logistic_regression/train/loss/add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/sub&quot;\\n  input: &quot;logistic_regression/train/loss/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;logistic_regression/train/loss/Neg&quot;\\n  input: &quot;logistic_regression/train/loss/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/weights&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/ToFloat_3/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  input: &quot;logistic_regression/train/loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/loss/Mul_2&quot;\\n  input: &quot;logistic_regression/train/loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;logistic_regression/train/loss/ToFloat_3/x&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/ones_like/Shape&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/Equal&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/zeros_like&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^logistic_regression/train/loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/Select&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/num_present&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/loss/Sum&quot;\\n  input: &quot;logistic_regression/train/loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;logistic_regression/train/loss/num_present&quot;\\n  input: &quot;logistic_regression/train/loss/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;logistic_regression/train/loss/num_present&quot;\\n  input: &quot;logistic_regression/train/loss/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;logistic_regression/train/loss/ones_like/Shape&quot;\\n  input: &quot;logistic_regression/train/loss/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Equal&quot;\\n  input: &quot;logistic_regression/train/loss/ones_like&quot;\\n  input: &quot;logistic_regression/train/loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;logistic_regression/train/loss/Sum_1&quot;\\n  input: &quot;logistic_regression/train/loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^logistic_regression/train/loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss/value&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Greater&quot;\\n  input: &quot;logistic_regression/train/loss/div&quot;\\n  input: &quot;logistic_regression/train/loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;logistic_regression/train/gradients/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Greater&quot;\\n  input: &quot;logistic_regression/train/gradients/Fill&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Greater&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/zeros_like&quot;\\n  input: &quot;logistic_regression/train/gradients/Fill&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;logistic_regression/train/loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Neg&quot;\\n  input: &quot;logistic_regression/train/loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv_1&quot;\\n  input: &quot;logistic_regression/train/loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Equal&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;logistic_regression/train/loss/Equal&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/zeros_like&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/div_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_1_grad/Tile&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/Mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Tile&quot;\\n  input: &quot;logistic_regression/train/loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/sub_2&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/mul_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Select_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Tile&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/num_present/Select&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights/ones_like_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_2_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Neg&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Neg_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/loss/Log_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/loss/sub&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/mul_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Neg_grad/Neg&quot;\\n  input: &quot;logistic_regression/train/loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;y&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Neg_grad/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/mul_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_1_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;logistic_regression/train/loss/add_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_1_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;logistic_regression/train/loss/add&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/train/loss/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_1_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_1_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/model/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/Log_grad/mul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Sum_1&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;logistic_regression/model/Sigmoid&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Neg&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/tuple/control_dependency&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/train/loss/sub_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/train/loss/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;logistic_regression/model/Sigmoid&quot;\\n  input: &quot;logistic_regression/train/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/model/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;logistic_regression/model/theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/model/Sigmoid_grad/SigmoidGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul_1&quot;\\n  input: &quot;^logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/train/gradients/logistic_regression/model/logits_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/GradientDescent/update_logistic_regression/model/theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;logistic_regression/model/theta&quot;\\n  input: &quot;logistic_regression/train/GradientDescent/learning_rate&quot;\\n  input: &quot;logistic_regression/train/gradients/logistic_regression/model/logits_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/train/GradientDescent/update_logistic_regression/model/theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss_loss/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;logistic_regression/train/loss_loss&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/train/loss_loss&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;logistic_regression/train/loss_loss/tags&quot;\\n  input: &quot;logistic_regression/train/loss/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/init/init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/model/theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;logistic_regression/save/save/Const&quot;\\n  input: &quot;logistic_regression/save/save/SaveV2/tensor_names&quot;\\n  input: &quot;logistic_regression/save/save/SaveV2/shape_and_slices&quot;\\n  input: &quot;logistic_regression/model/theta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logistic_regression/save/save/Const&quot;\\n  input: &quot;^logistic_regression/save/save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/save/save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;logistic_regression/save/save/Const&quot;\\n  input: &quot;logistic_regression/save/save/RestoreV2/tensor_names&quot;\\n  input: &quot;logistic_regression/save/save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logistic_regression/model/theta&quot;\\n  input: &quot;logistic_regression/save/save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logistic_regression/model/theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logistic_regression/save/save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^logistic_regression/save/save/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.21654012033140546&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
